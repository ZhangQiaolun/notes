{"characteristics": {"java": {"sourcefile": "JRecord.java", "class_name": "org/apache/hadoop/record/compiler/JRecord$CppRecord", "access_permissions": ["ACC_SUPER"], "major_version": 49, "method_names": ["<init>", "getTypeIDObjectString", "genDecl", "genSetRTIFilter", "genSetupRTIFields", "genCode"], "minor_version": 0, "const_pool_count": 443}}, "_id": "c46c5909-ebba-43c2-a589-6d356c50fb61", "verbose": {"java": {"signatures": ["Ljava/util/ArrayList<Lorg/apache/hadoop/record/compiler/JField<Lorg/apache/hadoop/record/compiler/JType$CppType;>;>;", "(Ljava/lang/String;Ljava/util/ArrayList<Lorg/apache/hadoop/record/compiler/JField<Lorg/apache/hadoop/record/compiler/JType;>;>;)V", "(Ljava/io/FileWriter;Ljava/io/FileWriter;Ljava/util/ArrayList<Ljava/lang/String;>;)V"], "constant strings": ["\\\\.", "::", "new ::hadoop::StructTypeID(", "::getTypeInfo().getFieldTypeInfos())", "  ", " ", ";\\n", "::setTypeFilter(rti.getNestedStructTypeInfo(\"", "\"));\\n", "void ", "::setupRtiFields() {\\n", "if (NULL == p_rio_rtiFilter) return;\\n", "if (NULL != p_rio_rtiFilterFields) return;\\n", "p_rio_rtiFilterFields = new int[p_rio_rtiFilter->getFieldTypeInfos().size()];\\n", "for (unsigned int _rio_i=0; _rio_i<p_rio_rtiFilter->getFieldTypeInfos().size(); _rio_i++) {\\n", "p_rio_rtiFilterFields[_rio_i] = 0;\\n", "}\\n", "for (unsigned int _rio_j=0; _rio_j<p_rio_recTypeInfo->getFieldTypeInfos().size(); _rio_j++) {\\n", "if (*(p_rio_rtiFilter->getFieldTypeInfos()[_rio_i]) == *(p_rio_recTypeInfo->getFieldTypeInfos()[_rio_j])) {\\n", "p_rio_rtiFilterFields[_rio_i] = _rio_j+1;\\n", "break;\\n", "namespace ", " {\\n", "class ", " : public ::hadoop::Record {\\n", "private:\\n", "static ::hadoop::RecordTypeInfo* p_rio_recTypeInfo;\\n", "static ::hadoop::RecordTypeInfo* p_rio_rtiFilter;\\n", "static int* p_rio_rtiFilterFields;\\n", "static ::hadoop::RecordTypeInfo* setupTypeInfo();\\n", "static void setupRtiFields();\\n", "virtual void deserializeWithoutFilter(::hadoop::IArchive& _rio_a, const char* _rio_tag);\\n", "public:\\n", "static const ::hadoop::RecordTypeInfo& getTypeInfo() {return *p_rio_recTypeInfo;}\\n", "static void setTypeFilter(const ::hadoop::RecordTypeInfo& rti);\\n", "static void setTypeFilter(const ::hadoop::RecordTypeInfo* prti);\\n", "virtual void serialize(::hadoop::OArchive& _rio_a, const char* _rio_tag) const;\\n", "virtual void deserialize(::hadoop::IArchive& _rio_a, const char* _rio_tag);\\n", "virtual const ::std::string& type() const;\\n", "virtual const ::std::string& signature() const;\\n", "virtual bool operator<(const ", "& peer_) const;\\n", "virtual bool operator==(const ", "virtual ~", "() {};\\n", "}; // end record ", "\\n", "} // end namespace ", "::hadoop::RecordTypeInfo* ", "::p", "_rio_recTypeInfo", " = ", "::setupTypeInfo();\\n", "_rio_rtiFilter", " = NULL;\\n", "int* ", "_rio_rtiFilterFields", " = NULL;\\n\\n", "::setupTypeInfo() {\\n", "::hadoop::RecordTypeInfo* p = new ::hadoop::RecordTypeInfo(\"", "\");\\n", "return p;\\n", "::setTypeFilter(const ", "::hadoop::RecordTypeInfo& rti) {\\n", "if (NULL != p_rio_rtiFilter) {\\n", "delete p_rio_rtiFilter;\\n", "p_rio_rtiFilter = new ::hadoop::RecordTypeInfo(rti);\\n", "if (NULL != p_rio_rtiFilterFields) {\\n", "delete p_rio_rtiFilterFields;\\n", "p_rio_rtiFilterFields = NULL;\\n", "::hadoop::RecordTypeInfo* prti) {\\n", "if (NULL != prti) {\\n", "setTypeFilter(*prti);\\n", "::serialize(::hadoop::OArchive& ", "_rio_a", ", const char* ", "_rio_tag", ") const {\\n", "_rio_a.startRecord(*this,_rio_tag);\\n", "_rio_a.serialize(", ",", ".length(),\"", ",\"", "_rio_a.endRecord(*this,_rio_tag);\\n", "return;\\n", "::deserializeWithoutFilter(::hadoop::IArchive& ", ") {\\n", "{\\nsize_t len=0; _rio_a.deserialize(", ",len,\"", "\");\\n}\\n", "_rio_a.deserialize(", "::deserialize(::hadoop::IArchive& ", "if (NULL == p_rio_rtiFilter) {\\n", "deserializeWithoutFilter(_rio_a, _rio_tag);\\n", "// if we\\'re here, we need to read based on version info\\n", "setupRtiFields();\\n", "else ", "if (", " == p", "[", "_rio_", "i]) {\\n", "else {\\n", "const std::vector< ::hadoop::FieldTypeInfo* >& typeInfos = p_rio_rtiFilter->getFieldTypeInfos();\\n", "::hadoop::Utils::skip(_rio_a, typeInfos[_rio_i]->getFieldID()->c_str(), *(typeInfos[_rio_i]->getTypeID()));\\n", "_rio_a.endRecord(*this, _rio_tag);\\n", "bool ", "::operator< (const ", "& peer_) const {\\n", "return (1\\n", "&& (", " < peer_.", ")\\n", ");\\n", "::operator== (const ", " == peer_.", "const ::std::string&", "::type() const {\\n", "static const ::std::string type_(\"", "return type_;\\n", "::signature() const {\\n", "static const ::std::string sig_(\"", "return sig_;\\n"], "JAVA String Analysis": {"combined strings entropy": 4.987174217894729, "obfuscated_data": {"base64": {"&& (": "static void setTypeFilter(const ::hadoop::RecordTypeInfo& rti);\\n", "if (": "static void setTypeFilter(const ::hadoop::RecordTypeInfo& rti);\\n"}, "substring_brute_force": {"_rio_": {"for (unsigned int _rio_j=0; _rio_j<p_rio_recTypeInfo->getFieldTypeInfos()_size(); _rio_j++) {\n": "for (unsigned int j=0; j<precTypeInfo->getFieldTypeInfos().size(); j++) {\\n", "p_rio_rtiFilterFields[_rio_i] = _rio_j+1;\n": "prtiFilterFields[i] = j+1;\\n", "::hadoop::Utils::skip(_rio_a, typeInfos[_rio_i]->getFieldID()->c_str(), *(typeInfos[_rio_i]->getTypeID()));\n": "::hadoop::Utils::skip(a, typeInfos[i]->getFieldID()->c_str(), *(typeInfos[i]->getTypeID()));\\n", "for (unsigned int _rio_i=0; _rio_i<p_rio_rtiFilter->getFieldTypeInfos()_size(); _rio_i++) {\n": "for (unsigned int i=0; i<prtiFilter->getFieldTypeInfos().size(); i++) {\\n", "if (*(p_rio_rtiFilter->getFieldTypeInfos()[_rio_i]) == *(p_rio_recTypeInfo->getFieldTypeInfos()[_rio_j])) {\n": "if (*(prtiFilter->getFieldTypeInfos()[i]) == *(precTypeInfo->getFieldTypeInfos()[j])) {\\n"}, "::": {"const std::vector< ::hadoop::FieldTypeInfo* >& typeInfos = p_rio_rtiFilter->getFieldTypeInfos();\n": "const stdvector< hadoopFieldTypeInfo* >& typeInfos = p_rio_rtiFilter->getFieldTypeInfos();\\n", "::deserializeWithoutFilter(::hadoop::IArchive& ": "deserializeWithoutFilter(hadoopIArchive& ", "::hadoop::Utils::skip(_rio_a, typeInfos[_rio_i]->getFieldID()->c_str(), *(typeInfos[_rio_i]->getTypeID()));\n": "hadoopUtilsskip(_rio_a, typeInfos[_rio_i]->getFieldID()->c_str(), *(typeInfos[_rio_i]->getTypeID()));\\n", "::deserialize(::hadoop::IArchive& ": "deserialize(hadoopIArchive& ", "::serialize(::hadoop::OArchive& ": "serialize(hadoopOArchive& ", "::hadoop::RecordTypeInfo* p = new ::hadoop::RecordTypeInfo(\"": "hadoopRecordTypeInfo* p = new hadoopRecordTypeInfo(\""}}}}}}, "metadata": {"mimetype": "application/x-java-applet", "sha1": "148ff49bf95d57876a50437f58e8f7c7306b5e6f", "file_name": "java_clean/3e5f765b67d3da535c091be35560e5b3fa59a16a3a2daa9fd35c7cf3e6947d83", "_id": "c46c5909-ebba-43c2-a589-6d356c50fb61", "score": 0, "entropy": 6.091156521090415, "libmagic": "compiled Java class data, version 49.0 (Java 1.5)", "file_size": 12310, "ssdeep": "384:zzZFmepyADF1FgFzF8Je6FIF1if0oO+a1p8syisWAAx/NheMOeFkA7PZB5ixW:zdFmepyADF1FgFzF8Je6FIF1iMoha1pV", "sha256": "3e5f765b67d3da535c091be35560e5b3fa59a16a3a2daa9fd35c7cf3e6947d83", "md5": "383f068f659d3ace67172c32209112cf", "parent_sha256": "3e5f765b67d3da535c091be35560e5b3fa59a16a3a2daa9fd35c7cf3e6947d83"}}